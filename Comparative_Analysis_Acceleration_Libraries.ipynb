{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lovnishverma/Python-Getting-Started/blob/main/Comparative_Analysis_Acceleration_Libraries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IC1eP-Z2Ikw"
      },
      "source": [
        "# **High-Performance Computing Benchmark: CPU vs. GPU**\n",
        "\n",
        "**Objective:** Demonstrate the computational bottleneck of standard Python loops compared to hardware-accelerated libraries.\n",
        "\n",
        "**The Task:** Perform a compute-bound trigonometric operation (`sin(x) * cos(x)`) on **10,000,000** data points.\n",
        "\n",
        "**The Methods:**\n",
        "1.  **Pure Python:** Standard Interpreter Loop (Baseline)\n",
        "2.  **NumPy:** CPU Vectorization (Standard Optimization)\n",
        "3.  **Numba:** JIT Compilation (Advanced CPU Optimization)\n",
        "4.  **CuPy:** GPU Acceleration (Parallel Processing on NVIDIA T4)"
      ],
      "id": "5IC1eP-Z2Ikw"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "P7Bd8pw72Ik1",
        "outputId": "f1ef8fc5-3936-4773-8008-53974e35769d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Environment Ready.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Environment Ready.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "GPU Detected: 1x NVIDIA T4\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">GPU Detected: 1x NVIDIA T4\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "from numba import jit, prange\n",
        "from tqdm import tqdm  # Progress bar for the slow Python loop\n",
        "from rich import print\n",
        "\n",
        "# Hardware Check\n",
        "gpu_count = cp.cuda.runtime.getDeviceCount()\n",
        "print(f\"Environment Ready.\")\n",
        "print(f\"GPU Detected: {gpu_count}x NVIDIA T4\")"
      ],
      "id": "P7Bd8pw72Ik1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBqBZM9r2Ik3"
      },
      "source": [
        "### 1. **Configuration**\n",
        "We define the dataset size at **10 Million**.\n",
        "\n",
        "*Note: Trigonometric functions (sine/cosine) are computationally expensive for the CPU, making this an ideal stress test.*"
      ],
      "id": "kBqBZM9r2Ik3"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "1GIhphTs2Ik4",
        "outputId": "f95c4c76-4278-4933-fcae-1fc04edd01a6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dataset Size: \u001b[1;36m10\u001b[0m,\u001b[1;36m000\u001b[0m,\u001b[1;36m000\u001b[0m elements\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Dataset Size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span> elements\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "N_SIZE = 10_000_000\n",
        "print(f\"Dataset Size: {N_SIZE:,} elements\")"
      ],
      "id": "1GIhphTs2Ik4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3yCS7YE2Ik4"
      },
      "source": [
        "### 2. **Baseline: Pure Python Loop**\n",
        "We iterate through the 10 million items using a standard `for` loop.\n",
        "\n",
        "**Warning:** This operation is extremely slow due to the Global Interpreter Lock (GIL) and lack of vectorization. A progress bar is included to visualize the processing time."
      ],
      "id": "v3yCS7YE2Ik4"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "x3jWgqDt2Ik5",
        "outputId": "6743c195-699a-4421-a3a4-9e7f74c1761e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running Pure Python implementation on \u001b[1;36m10\u001b[0m,\u001b[1;36m000\u001b[0m,\u001b[1;36m000\u001b[0m items\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Running Pure Python implementation on <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span> items<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Python Loop: 100%|██████████| 10000000/10000000 [00:03<00:00, 3165416.42it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Python Execution Time: \u001b[1;36m3.1683\u001b[0m seconds\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Python Execution Time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.1683</span> seconds\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def python_heavy_math(n):\n",
        "    result = 0.0\n",
        "    # TQDM adds a progress bar so we can see the slow execution speed\n",
        "    for x in tqdm(range(n), desc=\"Processing Python Loop\"):\n",
        "        result += math.sin(x) * math.cos(x)\n",
        "    return result\n",
        "\n",
        "print(f\"Running Pure Python implementation on {N_SIZE:,} items...\")\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "python_heavy_math(N_SIZE)\n",
        "t1 = time.perf_counter()\n",
        "\n",
        "time_python = t1 - t0\n",
        "print(f\"\\nPython Execution Time: {time_python:.4f} seconds\")"
      ],
      "id": "x3jWgqDt2Ik5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vskuRDMu2Ik5"
      },
      "source": [
        "### 3. **NumPy: Vectorization**\n",
        "We switch to NumPy, which pushes the loop execution to optimized C-code. While significantly faster, it is still bound by CPU clock speeds."
      ],
      "id": "vskuRDMu2Ik5"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "QfU8ELn52Ik5",
        "outputId": "90f2139d-aa51-45f2-caaf-5dda93a2d713"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running NumPy implementation\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Running NumPy implementation<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NumPy Execution Time: \u001b[1;36m0.2251\u001b[0m seconds\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">NumPy Execution Time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2251</span> seconds\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(f\"Running NumPy implementation...\")\n",
        "\n",
        "# Create Data\n",
        "data_np = np.arange(N_SIZE, dtype=np.float32)\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "# Vectorized Operation\n",
        "np.sum(np.sin(data_np) * np.cos(data_np))\n",
        "t1 = time.perf_counter()\n",
        "\n",
        "time_numpy = t1 - t0\n",
        "print(f\"NumPy Execution Time: {time_numpy:.4f} seconds\")"
      ],
      "id": "QfU8ELn52Ik5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-G6KE-42Ik6"
      },
      "source": [
        "### 4. **Numba: JIT Compilation**\n",
        "Using Just-In-Time (JIT) compilation to convert the Python function into machine code. This allows it to run at near-native C speeds on the CPU.\n",
        "\n",
        "*Note: A warmup run is performed first to compile the code, ensuring the benchmark measures only execution time.*"
      ],
      "id": "4-G6KE-42Ik6"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "rjV21u4R2Ik6",
        "outputId": "fc7b7dc9-78bb-4725-92c0-992432d2145e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running Numba implementation\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Running Numba implementation<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Numba Execution Time: \u001b[1;36m0.1056\u001b[0m seconds\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Numba Execution Time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1056</span> seconds\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "@jit(nopython=True, parallel=True)\n",
        "def numba_heavy_math(arr):\n",
        "    res = 0.0\n",
        "    for i in prange(len(arr)):\n",
        "        res += np.sin(arr[i]) * np.cos(arr[i])\n",
        "    return res\n",
        "\n",
        "print(f\"Running Numba implementation...\")\n",
        "# Warmup (Compilation)\n",
        "numba_heavy_math(data_np)\n",
        "\n",
        "# Benchmark\n",
        "t0 = time.perf_counter()\n",
        "numba_heavy_math(data_np)\n",
        "t1 = time.perf_counter()\n",
        "\n",
        "time_numba = t1 - t0\n",
        "print(f\"Numba Execution Time: {time_numba:.4f} seconds\")"
      ],
      "id": "rjV21u4R2Ik6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YrVF9Zv2Ik6"
      },
      "source": [
        "### 5. **CuPy: GPU Acceleration**\n",
        "We transfer the data to the GPU (VRAM) and execute the operation in parallel across thousands of CUDA cores.\n",
        "\n",
        "*Note: `cp.cuda.Stream.null.synchronize()` is used to ensure the timer waits for the GPU to finish calculations.*"
      ],
      "id": "2YrVF9Zv2Ik6"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "ATxULNo-2Ik7",
        "outputId": "701e8de3-3b1e-4d73-c773-6d73543b2190"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running CuPy implementation\u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Running CuPy implementation<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "CuPy Execution Time: \u001b[1;36m0.0030\u001b[0m seconds\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">CuPy Execution Time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0030</span> seconds\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(f\"Running CuPy implementation...\")\n",
        "\n",
        "# Transfer data to GPU\n",
        "data_cp = cp.arange(N_SIZE, dtype=cp.float32)\n",
        "\n",
        "# Warmup\n",
        "cp.sum(cp.sin(data_cp) * cp.cos(data_cp))\n",
        "cp.cuda.Stream.null.synchronize()\n",
        "\n",
        "# Benchmark\n",
        "t0 = time.perf_counter()\n",
        "cp.sum(cp.sin(data_cp) * cp.cos(data_cp))\n",
        "cp.cuda.Stream.null.synchronize()\n",
        "t1 = time.perf_counter()\n",
        "\n",
        "time_cupy = t1 - t0\n",
        "print(f\"CuPy Execution Time: {time_cupy:.4f} seconds\")"
      ],
      "id": "ATxULNo-2Ik7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t97H3JDf2Ik7"
      },
      "source": [
        "### 6. **Final Results Summary**"
      ],
      "id": "t97H3JDf2Ik7"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "AI49Q-0Y2Ik7",
        "outputId": "e3b4bb93-6df2-4036-ab32-ee680549a285"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "----------------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "BENCHMARK RESULTS \u001b[1m(\u001b[0mLower is Better\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">BENCHMARK RESULTS <span style=\"font-weight: bold\">(</span>Lower is Better<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "----------------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m1\u001b[0m. Pure Python: \u001b[1;36m3.1683\u001b[0m s\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Pure Python: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.1683</span> s\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m2\u001b[0m. NumPy \u001b[1m(\u001b[0mCPU\u001b[1m)\u001b[0m: \u001b[1;36m0.2251\u001b[0m s\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. NumPy <span style=\"font-weight: bold\">(</span>CPU<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2251</span> s\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m3\u001b[0m. Numba \u001b[1m(\u001b[0mCPU\u001b[1m)\u001b[0m: \u001b[1;36m0.1056\u001b[0m s\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Numba <span style=\"font-weight: bold\">(</span>CPU<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1056</span> s\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m4\u001b[0m. CuPy \u001b[1m(\u001b[0mGPU\u001b[1m)\u001b[0m:  \u001b[1;36m0.0030\u001b[0m s\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. CuPy <span style=\"font-weight: bold\">(</span>GPU<span style=\"font-weight: bold\">)</span>:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0030</span> s\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "----------------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "SPEEDUP FACTOR:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SPEEDUP FACTOR:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "CuPy is \u001b[1;36m75.\u001b[0m1x faster than NumPy\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">CuPy is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75.</span>1x faster than NumPy\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "CuPy is \u001b[1;36m1057.\u001b[0m5x faster than Python\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">CuPy is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1057.</span>5x faster than Python\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(f\"{'-'*40}\")\n",
        "print(\"BENCHMARK RESULTS (Lower is Better)\")\n",
        "print(f\"{'-'*40}\")\n",
        "print(f\"1. Pure Python: {time_python:.4f} s\")\n",
        "print(f\"2. NumPy (CPU): {time_numpy:.4f} s\")\n",
        "print(f\"3. Numba (CPU): {time_numba:.4f} s\")\n",
        "print(f\"4. CuPy (GPU):  {time_cupy:.4f} s\")\n",
        "print(f\"{'-'*40}\")\n",
        "print(f\"SPEEDUP FACTOR:\")\n",
        "print(f\"CuPy is {time_numpy / time_cupy:.1f}x faster than NumPy\")\n",
        "print(f\"CuPy is {time_python / time_cupy:.1f}x faster than Python\")"
      ],
      "id": "AI49Q-0Y2Ik7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subscribe to **Lovnish Verma** for more....\n",
        "\n",
        "*https://www.youtube.com/@lovnishverma*"
      ],
      "metadata": {
        "id": "5m-cf7ur3PYT"
      },
      "id": "5m-cf7ur3PYT"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}