{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl0L/7zqvLxQajjIrVlOjb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lovnishverma/Python-Getting-Started/blob/main/House_Price_Prediction_with_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **House Price Prediction with Neural Network**"
      ],
      "metadata": {
        "id": "GFMItQOA6Q9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You don't train a neural network. You let it struggle, fail, adapt, and repeat—until its failures look like intelligence\" - **Emmimal P. Alexander**."
      ],
      "metadata": {
        "id": "0TWerqc8MZNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, losses, metrics\n",
        "from rich import print # for preety outputs"
      ],
      "metadata": {
        "id": "2vQcw-Xm6lWc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Load Dataset\n",
        "url = \"https://raw.githubusercontent.com/lovnishverma/datasets/refs/heads/main/House%20Price%20India.csv\"\n",
        "data = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "ks9oT4hL6l02"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Shape:\", data.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "P-hTm8mp6nTw",
        "outputId": "5527ce2f-45c1-4de5-ca47-f677d9d5caf2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dataset Shape:\n",
              "\u001b[1m(\u001b[0m\u001b[1;36m14619\u001b[0m, \u001b[1;36m23\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Dataset Shape:\n",
              "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14619</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "First \u001b[1;36m5\u001b[0m rows:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "First <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> rows:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           id   Date  number of bedrooms  number of bathrooms  living area  \\\n",
              "\u001b[1;36m0\u001b[0m  \u001b[1;36m6762810635\u001b[0m  \u001b[1;36m42491\u001b[0m                   \u001b[1;36m4\u001b[0m                 \u001b[1;36m2.50\u001b[0m         \u001b[1;36m2920\u001b[0m   \n",
              "\u001b[1;36m1\u001b[0m  \u001b[1;36m6762810998\u001b[0m  \u001b[1;36m42491\u001b[0m                   \u001b[1;36m5\u001b[0m                 \u001b[1;36m2.75\u001b[0m         \u001b[1;36m2910\u001b[0m   \n",
              "\u001b[1;36m2\u001b[0m  \u001b[1;36m6762812605\u001b[0m  \u001b[1;36m42491\u001b[0m                   \u001b[1;36m4\u001b[0m                 \u001b[1;36m2.50\u001b[0m         \u001b[1;36m3310\u001b[0m   \n",
              "\u001b[1;36m3\u001b[0m  \u001b[1;36m6762812919\u001b[0m  \u001b[1;36m42491\u001b[0m                   \u001b[1;36m3\u001b[0m                 \u001b[1;36m2.00\u001b[0m         \u001b[1;36m2710\u001b[0m   \n",
              "\u001b[1;36m4\u001b[0m  \u001b[1;36m6762813105\u001b[0m  \u001b[1;36m42491\u001b[0m                   \u001b[1;36m3\u001b[0m                 \u001b[1;36m2.50\u001b[0m         \u001b[1;36m2600\u001b[0m   \n",
              "\n",
              "   lot area  number of floors  waterfront present  number of views  \\\n",
              "\u001b[1;36m0\u001b[0m      \u001b[1;36m4000\u001b[0m               \u001b[1;36m1.5\u001b[0m                   \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
              "\u001b[1;36m1\u001b[0m      \u001b[1;36m9480\u001b[0m               \u001b[1;36m1.5\u001b[0m                   \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
              "\u001b[1;36m2\u001b[0m     \u001b[1;36m42998\u001b[0m               \u001b[1;36m2.0\u001b[0m                   \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
              "\u001b[1;36m3\u001b[0m      \u001b[1;36m4500\u001b[0m               \u001b[1;36m1.5\u001b[0m                   \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
              "\u001b[1;36m4\u001b[0m      \u001b[1;36m4750\u001b[0m               \u001b[1;36m1.0\u001b[0m                   \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
              "\n",
              "   condition of the house  \u001b[33m...\u001b[0m  Built Year  Renovation Year  Postal Code  \\\n",
              "\u001b[1;36m0\u001b[0m                       \u001b[1;36m5\u001b[0m  \u001b[33m...\u001b[0m        \u001b[1;36m1909\u001b[0m                \u001b[1;36m0\u001b[0m       \u001b[1;36m122004\u001b[0m   \n",
              "\u001b[1;36m1\u001b[0m                       \u001b[1;36m3\u001b[0m  \u001b[33m...\u001b[0m        \u001b[1;36m1939\u001b[0m                \u001b[1;36m0\u001b[0m       \u001b[1;36m122004\u001b[0m   \n",
              "\u001b[1;36m2\u001b[0m                       \u001b[1;36m3\u001b[0m  \u001b[33m...\u001b[0m        \u001b[1;36m2001\u001b[0m                \u001b[1;36m0\u001b[0m       \u001b[1;36m122005\u001b[0m   \n",
              "\u001b[1;36m3\u001b[0m                       \u001b[1;36m4\u001b[0m  \u001b[33m...\u001b[0m        \u001b[1;36m1929\u001b[0m                \u001b[1;36m0\u001b[0m       \u001b[1;36m122006\u001b[0m   \n",
              "\u001b[1;36m4\u001b[0m                       \u001b[1;36m4\u001b[0m  \u001b[33m...\u001b[0m        \u001b[1;36m1951\u001b[0m                \u001b[1;36m0\u001b[0m       \u001b[1;36m122007\u001b[0m   \n",
              "\n",
              "   Lattitude  Longitude  living_area_renov  lot_area_renov  \\\n",
              "\u001b[1;36m0\u001b[0m    \u001b[1;36m52.8878\u001b[0m   \u001b[1;36m-114.470\u001b[0m               \u001b[1;36m2470\u001b[0m            \u001b[1;36m4000\u001b[0m   \n",
              "\u001b[1;36m1\u001b[0m    \u001b[1;36m52.8852\u001b[0m   \u001b[1;36m-114.468\u001b[0m               \u001b[1;36m2940\u001b[0m            \u001b[1;36m6600\u001b[0m   \n",
              "\u001b[1;36m2\u001b[0m    \u001b[1;36m52.9532\u001b[0m   \u001b[1;36m-114.321\u001b[0m               \u001b[1;36m3350\u001b[0m           \u001b[1;36m42847\u001b[0m   \n",
              "\u001b[1;36m3\u001b[0m    \u001b[1;36m52.9047\u001b[0m   \u001b[1;36m-114.485\u001b[0m               \u001b[1;36m2060\u001b[0m            \u001b[1;36m4500\u001b[0m   \n",
              "\u001b[1;36m4\u001b[0m    \u001b[1;36m52.9133\u001b[0m   \u001b[1;36m-114.590\u001b[0m               \u001b[1;36m2380\u001b[0m            \u001b[1;36m4750\u001b[0m   \n",
              "\n",
              "   Number of schools nearby  Distance from the airport    Price  \n",
              "\u001b[1;36m0\u001b[0m                         \u001b[1;36m2\u001b[0m                         \u001b[1;36m51\u001b[0m  \u001b[1;36m1400000\u001b[0m  \n",
              "\u001b[1;36m1\u001b[0m                         \u001b[1;36m1\u001b[0m                         \u001b[1;36m53\u001b[0m  \u001b[1;36m1200000\u001b[0m  \n",
              "\u001b[1;36m2\u001b[0m                         \u001b[1;36m3\u001b[0m                         \u001b[1;36m76\u001b[0m   \u001b[1;36m838000\u001b[0m  \n",
              "\u001b[1;36m3\u001b[0m                         \u001b[1;36m1\u001b[0m                         \u001b[1;36m51\u001b[0m   \u001b[1;36m805000\u001b[0m  \n",
              "\u001b[1;36m4\u001b[0m                         \u001b[1;36m1\u001b[0m                         \u001b[1;36m67\u001b[0m   \u001b[1;36m790000\u001b[0m  \n",
              "\n",
              "\u001b[1m[\u001b[0m\u001b[1;36m5\u001b[0m rows x \u001b[1;36m23\u001b[0m columns\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">           id   Date  number of bedrooms  number of bathrooms  living area  \\\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6762810635</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42491</span>                   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.50</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2920</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6762810998</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42491</span>                   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.75</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2910</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6762812605</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42491</span>                   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.50</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3310</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6762812919</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42491</span>                   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.00</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2710</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6762813105</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42491</span>                   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.50</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2600</span>   \n",
              "\n",
              "   lot area  number of floors  waterfront present  number of views  \\\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4000</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5</span>                   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9480</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5</span>                   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42998</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>                   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4500</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5</span>                   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4750</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>                   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>   \n",
              "\n",
              "   condition of the house  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>  Built Year  Renovation Year  Postal Code  \\\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1909</span>                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">122004</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1939</span>                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">122004</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2001</span>                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">122005</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1929</span>                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">122006</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1951</span>                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">122007</span>   \n",
              "\n",
              "   Lattitude  Longitude  living_area_renov  lot_area_renov  \\\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52.8878</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-114.470</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2470</span>            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4000</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52.8852</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-114.468</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2940</span>            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6600</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52.9532</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-114.321</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3350</span>           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42847</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52.9047</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-114.485</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2060</span>            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4500</span>   \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52.9133</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-114.590</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2380</span>            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4750</span>   \n",
              "\n",
              "   Number of schools nearby  Distance from the airport    Price  \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1400000</span>  \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1200000</span>  \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">838000</span>  \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>                         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">805000</span>  \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>                         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">790000</span>  \n",
              "\n",
              "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> rows x <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> columns<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Select Features and Target\n",
        "# We'll drop columns not useful for learning (like id, Date, Postal Code, coordinates etc.)\n",
        "X = data.drop(columns=[\"id\", \"Date\", \"Postal Code\", \"Price\"])\n",
        "y = data[\"Price\"]"
      ],
      "metadata": {
        "id": "V6HJEyhT6op7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "u0uVCXgW6q-P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: Normalize Features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "w9PWY-su6sT3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Build Neural Network\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1],)),   # Explicit input layer\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(1)  # Regression → single output (no activation)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=losses.MeanSquaredError(),\n",
        "    metrics=[metrics.MeanAbsoluteError()]\n",
        ")"
      ],
      "metadata": {
        "id": "UA1pRhC56vKO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: Train the Model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3m28Ie26wcz",
        "outputId": "4d29a297-cf6a-4c35-c88d-a4caf302468b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 414223007744.0000 - mean_absolute_error: 535153.8750 - val_loss: 437428977664.0000 - val_mean_absolute_error: 538496.5000\n",
            "Epoch 2/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 427315429376.0000 - mean_absolute_error: 536260.1250 - val_loss: 424519925760.0000 - val_mean_absolute_error: 530358.0000\n",
            "Epoch 3/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 422889390080.0000 - mean_absolute_error: 530041.0000 - val_loss: 393514713088.0000 - val_mean_absolute_error: 510238.9062\n",
            "Epoch 4/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 394739089408.0000 - mean_absolute_error: 505432.4375 - val_loss: 344346460160.0000 - val_mean_absolute_error: 476087.5625\n",
            "Epoch 5/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 323649273856.0000 - mean_absolute_error: 468011.1875 - val_loss: 281592037376.0000 - val_mean_absolute_error: 427370.6875\n",
            "Epoch 6/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 246578708480.0000 - mean_absolute_error: 412671.8125 - val_loss: 216096604160.0000 - val_mean_absolute_error: 367529.1562\n",
            "Epoch 7/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 196232609792.0000 - mean_absolute_error: 349778.0625 - val_loss: 161734524928.0000 - val_mean_absolute_error: 308035.7500\n",
            "Epoch 8/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152586567680.0000 - mean_absolute_error: 296705.4062 - val_loss: 122853433344.0000 - val_mean_absolute_error: 259294.1406\n",
            "Epoch 9/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 113374863360.0000 - mean_absolute_error: 248468.8906 - val_loss: 98873376768.0000 - val_mean_absolute_error: 228856.4219\n",
            "Epoch 10/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 90901577728.0000 - mean_absolute_error: 220619.3438 - val_loss: 85562474496.0000 - val_mean_absolute_error: 211462.1562\n",
            "Epoch 11/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 80805683200.0000 - mean_absolute_error: 208399.1719 - val_loss: 78581293056.0000 - val_mean_absolute_error: 201958.0469\n",
            "Epoch 12/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 71002341376.0000 - mean_absolute_error: 194657.0312 - val_loss: 74456883200.0000 - val_mean_absolute_error: 196055.0625\n",
            "Epoch 13/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 66131173376.0000 - mean_absolute_error: 191206.2812 - val_loss: 71709589504.0000 - val_mean_absolute_error: 191884.5156\n",
            "Epoch 14/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 71370661888.0000 - mean_absolute_error: 190905.5312 - val_loss: 69645606912.0000 - val_mean_absolute_error: 188540.6719\n",
            "Epoch 15/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 62776242176.0000 - mean_absolute_error: 185171.3125 - val_loss: 67849039872.0000 - val_mean_absolute_error: 185560.0938\n",
            "Epoch 16/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 65479749632.0000 - mean_absolute_error: 182738.1094 - val_loss: 66287300608.0000 - val_mean_absolute_error: 182772.7500\n",
            "Epoch 17/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 60009967616.0000 - mean_absolute_error: 179746.6250 - val_loss: 64745578496.0000 - val_mean_absolute_error: 180139.4844\n",
            "Epoch 18/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 61353836544.0000 - mean_absolute_error: 178322.5781 - val_loss: 63396233216.0000 - val_mean_absolute_error: 177446.3125\n",
            "Epoch 19/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 56564047872.0000 - mean_absolute_error: 173262.1875 - val_loss: 62064070656.0000 - val_mean_absolute_error: 174747.0938\n",
            "Epoch 20/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55940624384.0000 - mean_absolute_error: 171187.4375 - val_loss: 60752388096.0000 - val_mean_absolute_error: 172095.0000\n",
            "Epoch 21/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56261136384.0000 - mean_absolute_error: 171334.2031 - val_loss: 59439296512.0000 - val_mean_absolute_error: 169496.1562\n",
            "Epoch 22/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55616360448.0000 - mean_absolute_error: 167894.4844 - val_loss: 58166116352.0000 - val_mean_absolute_error: 166831.6562\n",
            "Epoch 23/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 58809327616.0000 - mean_absolute_error: 168480.8125 - val_loss: 57011515392.0000 - val_mean_absolute_error: 164125.3906\n",
            "Epoch 24/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 49505533952.0000 - mean_absolute_error: 159813.7031 - val_loss: 55747506176.0000 - val_mean_absolute_error: 161531.3125\n",
            "Epoch 25/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50552377344.0000 - mean_absolute_error: 158424.9062 - val_loss: 54524489728.0000 - val_mean_absolute_error: 158916.1562\n",
            "Epoch 26/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50673221632.0000 - mean_absolute_error: 157680.0156 - val_loss: 53409890304.0000 - val_mean_absolute_error: 156255.6406\n",
            "Epoch 27/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54458839040.0000 - mean_absolute_error: 154351.5000 - val_loss: 52333830144.0000 - val_mean_absolute_error: 153568.2031\n",
            "Epoch 28/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 44920733696.0000 - mean_absolute_error: 150369.9531 - val_loss: 51169816576.0000 - val_mean_absolute_error: 151002.0469\n",
            "Epoch 29/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 46643417088.0000 - mean_absolute_error: 149042.5781 - val_loss: 50052743168.0000 - val_mean_absolute_error: 148434.8750\n",
            "Epoch 30/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 42785349632.0000 - mean_absolute_error: 142803.0469 - val_loss: 49024540672.0000 - val_mean_absolute_error: 145868.3438\n",
            "Epoch 31/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 40419508224.0000 - mean_absolute_error: 140332.0312 - val_loss: 48055533568.0000 - val_mean_absolute_error: 143242.7031\n",
            "Epoch 32/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 43600580608.0000 - mean_absolute_error: 142910.0312 - val_loss: 47171346432.0000 - val_mean_absolute_error: 140657.7656\n",
            "Epoch 33/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 44322770944.0000 - mean_absolute_error: 139010.3125 - val_loss: 46387212288.0000 - val_mean_absolute_error: 138162.0312\n",
            "Epoch 34/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 45966950400.0000 - mean_absolute_error: 140076.5312 - val_loss: 45531840512.0000 - val_mean_absolute_error: 135920.3281\n",
            "Epoch 35/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38593347584.0000 - mean_absolute_error: 132558.0781 - val_loss: 44713721856.0000 - val_mean_absolute_error: 133809.4375\n",
            "Epoch 36/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37614473216.0000 - mean_absolute_error: 130825.7812 - val_loss: 44025131008.0000 - val_mean_absolute_error: 131708.6250\n",
            "Epoch 37/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39427424256.0000 - mean_absolute_error: 131020.0625 - val_loss: 43396964352.0000 - val_mean_absolute_error: 129742.7656\n",
            "Epoch 38/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 42365943808.0000 - mean_absolute_error: 129218.0625 - val_loss: 42834059264.0000 - val_mean_absolute_error: 127925.3516\n",
            "Epoch 39/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 38473453568.0000 - mean_absolute_error: 126840.9688 - val_loss: 42338652160.0000 - val_mean_absolute_error: 126238.6797\n",
            "Epoch 40/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 37654491136.0000 - mean_absolute_error: 125463.5859 - val_loss: 41835507712.0000 - val_mean_absolute_error: 124843.0781\n",
            "Epoch 41/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 35910483968.0000 - mean_absolute_error: 122104.1484 - val_loss: 41372057600.0000 - val_mean_absolute_error: 123600.7422\n",
            "Epoch 42/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36728532992.0000 - mean_absolute_error: 123214.8828 - val_loss: 40975544320.0000 - val_mean_absolute_error: 122510.1406\n",
            "Epoch 43/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35064352768.0000 - mean_absolute_error: 120248.6719 - val_loss: 40656846848.0000 - val_mean_absolute_error: 121464.2969\n",
            "Epoch 44/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35489017856.0000 - mean_absolute_error: 120184.0391 - val_loss: 40361271296.0000 - val_mean_absolute_error: 120577.1953\n",
            "Epoch 45/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35583889408.0000 - mean_absolute_error: 119904.4062 - val_loss: 40091115520.0000 - val_mean_absolute_error: 119809.1406\n",
            "Epoch 46/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35116285952.0000 - mean_absolute_error: 118370.8125 - val_loss: 39880765440.0000 - val_mean_absolute_error: 119003.6016\n",
            "Epoch 47/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36295593984.0000 - mean_absolute_error: 117744.8125 - val_loss: 39645577216.0000 - val_mean_absolute_error: 118417.7734\n",
            "Epoch 48/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 37274308608.0000 - mean_absolute_error: 118463.1953 - val_loss: 39432429568.0000 - val_mean_absolute_error: 117877.1016\n",
            "Epoch 49/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 39520366592.0000 - mean_absolute_error: 119111.6172 - val_loss: 39356448768.0000 - val_mean_absolute_error: 117073.9297\n",
            "Epoch 50/50\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 34384723968.0000 - mean_absolute_error: 116242.5625 - val_loss: 39058046976.0000 - val_mean_absolute_error: 116945.0391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8: Evaluate Model\n",
        "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nMean Absolute Error on Test Data: {mae:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1BwZZYyA6x1T",
        "outputId": "35339790-7455-465a-d821-3dfda3c76fbc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Mean Absolute Error on Test Data: \u001b[1;36m116945.04\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Mean Absolute Error on Test Data: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">116945.04</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You successfully trained and evaluated your **House Price Neural Network**.\n",
        "\n",
        "The result you got is:\n",
        "\n",
        "```\n",
        "Mean Absolute Error on Test Data: 119124.56\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### What does this mean?\n",
        "\n",
        "* **Mean Absolute Error (MAE)** tells us, *on average*, how far the predicted prices are from the true prices.\n",
        "* In your case → **₹119,124.56** (≈ 1.2 lakh) is the average difference between predicted and actual house prices.\n",
        "* Example:\n",
        "\n",
        "  * If a real house costs ₹12,00,000 → your model might predict somewhere around ₹10,80,000 to ₹13,20,000.\n",
        "  * Some predictions will be closer, some further, but **on average the error is \\~1.2 lakh**.\n",
        "\n",
        "---\n",
        "\n",
        "### How to Improve Accuracy?\n",
        "\n",
        "Here are beginner-friendly steps you can experiment with:\n",
        "\n",
        "1. **Train longer**\n",
        "\n",
        "   * Increase `epochs=100` or more.\n",
        "\n",
        "2. **More layers / neurons**\n",
        "\n",
        "   * Example:\n",
        "\n",
        "     ```python\n",
        "     model = keras.Sequential([\n",
        "         layers.Dense(128, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "         layers.Dense(64, activation=\"relu\"),\n",
        "         layers.Dense(32, activation=\"relu\"),\n",
        "         layers.Dense(1)\n",
        "     ])\n",
        "     ```\n",
        "\n",
        "3. **Feature engineering**\n",
        "\n",
        "   * Some columns (like `Renovation Year`, `lot_area_renov`) may not be strongly related. Try removing or transforming features.\n",
        "\n",
        "4. **Use `log` transform for Price**\n",
        "\n",
        "   * Prices are usually very skewed. Training on `log(Price)` often helps.\n",
        "\n",
        "5. **Try advanced models**\n",
        "\n",
        "   * Random Forests or Gradient Boosting sometimes perform better on tabular datasets.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "OCQcbK9VKgVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* For tabular regression, tree-based ensembles (RF, GBM, XGBoost, LightGBM, CatBoost) often outperform Neural Networks.\n",
        "\n",
        "* Yes, in the real world, if your only goal is accuracy on house prices, a Random Forest or XGBoost might outperform your neural network with less work."
      ],
      "metadata": {
        "id": "HoKXU9y79Fz6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "9FF3z2d058KP",
        "outputId": "a2068762-a0eb-44f6-b826-9bb1c4870b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Predicted Price: \u001b[1;36m515605.91\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Predicted Price: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">515605.91</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Actual Price   : \u001b[1;36m546800\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Actual Price   : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">546800</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# STEP 9: Make Prediction (example: first test house)\n",
        "sample = X_test[0].reshape(1, -1)\n",
        "predicted_price = model.predict(sample)[0][0]\n",
        "print(f\"\\nPredicted Price: {predicted_price:.2f}\")\n",
        "print(f\"Actual Price   : {y_test.iloc[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 10: Save Model (old way - not recommended)\n",
        "# model.save(\"house_price_model.h5\")\n",
        "# print(\"\\nModel saved as 'house_price_model.h5'\")\n",
        "\n",
        "# STEP 10: Save Model (Modern way and Recommended)\n",
        "model.save(\"house_price_model.keras\")\n",
        "print(\"\\nModel saved as 'house_price_model.keras'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Cuf5w5be6z7R",
        "outputId": "8d265f3e-378a-47ea-a871-d1f94943f7cd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Model saved as \u001b[32m'house_price_model.keras'\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Model saved as <span style=\"color: #008000; text-decoration-color: #008000\">'house_price_model.keras'</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 11: Load Saved Model\n",
        "\n",
        "# (Legacy) Load .h5 model (Not Recommended)\n",
        "# loaded_model = keras.models.load_model(\"house_price_model.h5\")\n",
        "\n",
        "# Load .keras model (Modern way and Recommended)\n",
        "loaded_model = keras.models.load_model(\"house_price_model.keras\")\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8mPKax6k7CU3",
        "outputId": "82029e0d-de3b-4578-e512-d4468c4a9530"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Model loaded successfully!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Model loaded successfully!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 12: Predict from Saved Model\n",
        "new_sample = X_test[1].reshape(1, -1)\n",
        "loaded_predicted_price = loaded_model.predict(new_sample)[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwfycMoy7PP4",
        "outputId": "2bf0ff6e-1ffe-4efd-98f7-e8f77e796451"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nPrediction from loaded model: {loaded_predicted_price:.2f}\")\n",
        "print(f\"Actual Price: {y_test.iloc[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "ob8NUesp7CzA",
        "outputId": "c572ff62-a06f-4d16-bb23-cf9a90e1f989"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Prediction from loaded model: \u001b[1;36m433529.03\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Prediction from loaded model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">433529.03</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Actual Price: \u001b[1;36m550000\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Actual Price: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">550000</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "###Key Notes:\n",
        "\n",
        "* **Scaling is important** in neural networks (we used `StandardScaler`).\n",
        "* For **regression**, the last layer has `1` unit and **no activation**.\n",
        "* We use **MSE (Mean Squared Error)** as loss, and **MAE (Mean Absolute Error)** as an easy-to-understand metric.\n",
        "* For tabular regression, tree-based ensembles (RF, GBM, XGBoost, LightGBM, CatBoost) often outperform Neural Networks.\n",
        "* Model prediction gives a **continuous price**, not a class.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "zLiTk5_56Z37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.align import Align\n",
        "\n",
        "console = Console()\n",
        "\n",
        "content = Align.center(\n",
        "    \"[bold cyan]© Lovnish Verma 2025[/bold cyan]\\nAll Rights Reserved\",\n",
        "    vertical=\"middle\"\n",
        ")\n",
        "\n",
        "console.print(\n",
        "    Panel(\n",
        "        content,\n",
        "        border_style=\"green\",\n",
        "        title=\"Copyright\",\n",
        "        subtitle=\"Neural Network Tutorial\",\n",
        "        expand=True\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "XVkNKogj-Z9Q",
        "outputId": "8fa23bac-6709-48d2-d4be-c7caa56aa749"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m╭─\u001b[0m\u001b[32m──────────────────────────────────────────────────\u001b[0m\u001b[32m Copyright \u001b[0m\u001b[32m──────────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                              \u001b[1;36m© Lovnish Verma 2025\u001b[0m                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                              All Rights Reserved                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m╰─\u001b[0m\u001b[32m───────────────────────────────────────────\u001b[0m\u001b[32m Neural Network Tutorial \u001b[0m\u001b[32m───────────────────────────────────────────\u001b[0m\u001b[32m─╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────────────────────── Copyright ───────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                              <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">© Lovnish Verma 2025</span>                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                              All Rights Reserved                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────── Neural Network Tutorial ────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}